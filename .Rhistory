kernel_width    = .1,
feature_select  = "highest_weights")
getwd()
library(readr)
Data_Scientist_Test_Data <- read_csv("Downloads/Data Scientist_Test_Data.csv")
View(Data_Scientist_Test_Data)
Data_Scientist_Test_Data <- read_csv("Downloads/Data Scientist_Test_Data.csv") %>%
select(organization_id:cc)
library(dplyr)
Data_Scientist_Test_Data <- read_csv("Downloads/Data Scientist_Test_Data.csv") %>%
select(organization_id:cc)
Data_Scientist_Test_Data <- read_csv("Downloads/Data Scientist_Test_Data.csv") %>%
select("organization_id":"cc")
Data_Scientist_Test_Data <- read_csv("~/Downloads/Data Scientist_Test_Data.csv") %>%
select("organization_id":"cc")
View(Data_Scientist_Test_Data)
Data_Scientist_Test_Data %>% str()
library(readr)
Data_Scientist_Test_Data <- read_csv("Downloads/Data Scientist_Test_Data.csv",
locale = locale(asciify = TRUE))
View(Data_Scientist_Test_Data)
Data_Scientist_Test_Data <- read_csv("~/Downloads/Data Scientist_Test_Data.csv") %>%
select("organization_id":"cc")
For (var in colnames(Data_Scientist_Test_Data)) {
For (var %in% colnames(Data_Scientist_Test_Data)) {
for(var in colnames(Data_Scientist_Test_Data)) {
attr(Data_Scientist_Test_Data[,deparse(as.name(var))], "ATT_1") <- NULL
attr(Data_Scientist_Test_Data[,deparse(as.name(var))], "ATT_2") <- NULL
}
for(var in colnames(Data_Scientist_Test_Data)) {
attr(Data_Scientist_Test_Data[,deparse(as.name(var))], "spec") <- NULL
attr(Data_Scientist_Test_Data[,deparse(as.name(var))], "ATT_2") <- NULL
}
for(var in colnames(Data_Scientist_Test_Data)) {
attr(Data_Scientist_Test_Data[,deparse(as.name(var))], "spec") <- NULL
}
Data_Scientist_Test_Data_source_0 <- readRDS("~/Downloads/Data_Scientist_Test_Data_source_0.rds")
ds_test_data <- readRDS("~/Downloads/Data_Scientist_Test_Data_source_0.rds")
ds_test_data %>% glimpse()
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(ds_test_data)), size = smp_size)
smp_size <- floor(0.75 * nrow(ds_test_data))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(ds_test_data)), size = smp_size)
train_tbl <- ds_test_data[train_ind, ]
test_tbl <- ds_test_data[-train_ind, ]
h2o.init()        # Fire up h2o
h2o.no_progress() # Turn off progress bars
# Convert to H2OFrame objects
train_h2o <- as.h2o(train_tbl)
valid_h2o <- as.h2o(valid_tbl)
test_h2o  <- as.h2o(test_tbl)
valid_size <- floor(.50 * nrow(ds_test_data) - train_size)
train_size <- floor(0.75 * nrow(ds_test_data))
valid_size <- floor(.50 * nrow(ds_test_data) - train_size)
train_size
valid_size
valid_size <- floor(.50 * (nrow(ds_test_data)-train_size))
valid_size
valid_ind <- sample(seq_len(nrow(ds_test_data[-train_ind, ])), size = valid_size)
valid_ind
ds_test_data[c(-train_ind,-valid_ind), ]
ds_test_data[c(-train_ind,-valid_ind), ]
ds_test_data[c(-train_ind,-valid_ind), ]
ds_test_data[c(-train_ind,-valid_ind), ]
ds_test_data[c(-train_ind,-valid_ind), ]
train_ind
valid_ind
valid_tbl <- ds_test_data[valid_ind, ]
valid_tbl
valid_ind
ds_test_data[valid_ind, ]
train_tbl <- ds_test_data[train_ind, ]
train_tbl
train_ind <- sample(seq_len(nrow(mtcars)), size = smp_size)
set.seed(123)
train_ind <- sample(seq_len(nrow(mtcars)), size = smp_size)
smp_size <- floor(0.75 * nrow(mtcars))
set.seed(123)
train_ind <- sample(seq_len(nrow(mtcars)), size = smp_size)
train_ind
valid_ind
valid_tbl <- ds_test_data[valid_ind, ]
valid_tbl
View(valid_tbl)
test_ind <- sample(seq_len(nrow(ds_test_data[c(-train_ind,-valid_ind), ])), size = valid_size)
ds_test_data[c(-train_ind,-valid_ind), ]
test_tbl <- ds_test_data[c(-train_ind,-valid_ind), ]
test_tbl <- ds_test_data[-c(train_ind,valid_ind), ]
test_tbl <- ds_test_data[-c(train_ind,valid_ind), ]
test_tbl <- ds_test_data[-train_ind, ]
test_ind
test_tbl <- ds_test_data[test_ind, ]
train_h2o <- as.h2o(train_tbl)
valid_h2o <- as.h2o(valid_tbl)
test_h2o  <- as.h2o(test_tbl)
# Set names for h2o
y <- "cc"
x <- setdiff(names(train_h2o), y)
automl_models_h2o <- h2o.automl(
project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
max_runtime_secs = 60,
stopping_metric = "deviance")
automl_leader <- automl_models_h2o@leader
# Get Results
pred_h2o <- h2o.predict(automl_leader, test_h2o)
h2o.performance(automl_leader, test_h2o)
h2o.varimp(automl_leader)
h2o.varimp_plot(automl_leader, 20)
h2o.download_mojo(automl_leader, "~/Downloads/", FALSE)
automl_models_h2o
as.factor(y)
automl_models_h2o <- h2o.automl(
project_name = "your_moms",
x = x,
y = as.factor(y),
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
max_runtime_secs = 60,
stopping_metric = "AUC"
, sort_metric = "AUC")
ds_test_data <- ds_test_data %>%
mutate(cc = as.factor(cc))
## 75% of the sample size for train, 12.5% for validation & test
train_size <- floor(0.75 * nrow(ds_test_data))
valid_size <- floor(.50 * (nrow(ds_test_data)-train_size))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(ds_test_data)), size = train_size)
train_tbl <- ds_test_data[train_ind, ]
valid_ind <- sample(seq_len(nrow(ds_test_data[-train_ind, ])), size = valid_size)
valid_tbl <- ds_test_data[valid_ind, ]
test_ind <- sample(seq_len(nrow(ds_test_data[c(-train_ind,-valid_ind), ])), size = valid_size)
test_tbl <- ds_test_data[test_ind, ]
h2o.init()        # Fire up h2o
h2o.no_progress() # Turn off progress bars
# Convert to H2OFrame objects
train_h2o <- as.h2o(train_tbl)
valid_h2o <- as.h2o(valid_tbl)
test_h2o  <- as.h2o(test_tbl)
# Set names for h2o
y <- "cc"
x <- setdiff(names(train_h2o), y)
# linear regression model used, but can use any model
automl_models_h2o <- h2o.automl(
project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
max_runtime_secs = 60,
stopping_metric = "deviance")
automl_models_h2o <- h2o.automl(
project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
max_runtime_secs = 60,
stopping_metric = "AUC"
, sort_metric = "AUC")
# Convert to H2OFrame objects
train_h2o <- as.h2o(train_tbl)
valid_h2o <- as.h2o(valid_tbl)
test_h2o  <- as.h2o(test_tbl)
# Set names for h2o
y <- "cc"
x <- setdiff(names(train_h2o), y)
automl_models_h2o <- h2o.automl(
project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
max_runtime_secs = 60,
stopping_metric = "AUC"
, sort_metric = "AUC")
View(train_obs)
ds_test_data_clean <- ds_test_data %>%
select_if(~ !is.Date(.)) %>%
select_if(~ !any(is.na(.))) %>%
mutate_if(is.ordered, ~ as.character(.) %>% as.factor)
library(h2o)        # Awesome ML Library
library(timetk)     # Toolkit for working with time series in R
library(tidyquant)  # Loads tidyverse, financial pkgs, used to get data
ds_test_data_clean <- ds_test_data %>%
select_if(~ !is.Date(.)) %>%
select_if(~ !any(is.na(.))) %>%
mutate_if(is.ordered, ~ as.character(.) %>% as.factor)
ds_test_data_clean
ds_test_data <- ds_test_data_clean %>%
mutate(cc = as.factor(cc))
# Split into training, validation and test sets
## 75% of the sample size for train, 12.5% for validation & test
train_size <- floor(0.75 * nrow(ds_test_data))
valid_size <- floor(.50 * (nrow(ds_test_data)-train_size))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(ds_test_data)), size = train_size)
train_tbl <- ds_test_data[train_ind, ]
valid_ind <- sample(seq_len(nrow(ds_test_data[-train_ind, ])), size = valid_size)
valid_tbl <- ds_test_data[valid_ind, ]
test_ind <- sample(seq_len(nrow(ds_test_data[c(-train_ind,-valid_ind), ])), size = valid_size)
test_tbl <- ds_test_data[test_ind, ]
train_h2o <- as.h2o(train_tbl)
valid_h2o <- as.h2o(valid_tbl)
test_h2o  <- as.h2o(test_tbl)
# Set names for h2o
y <- "cc"
x <- setdiff(names(train_h2o), y)
automl_models_h2o <- h2o.automl(
project_name = "your_mom",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
max_runtime_secs = 60,
stopping_metric = "AUC"
, sort_metric = "AUC")
automl_leader <- automl_models_h2o@leader
# Get Results
pred_h2o <- h2o.predict(automl_leader, test_h2o)
h2o.performance(automl_leader, test_h2o)
h2o.varimp(automl_leader)
h2o.varimp_plot(automl_leader, 20)
h2o.download_mojo(automl_leader, "~/Downloads/", FALSE)
h2o.partialPlot(automl_leader, data = train_h2o, cols = "MarketingSales")
ds_test_data_clean <- ds_test_data %>%
select(-organization_id) %>%
select_if(~ !is.Date(.)) %>%
select_if(~ !any(is.na(.))) %>%
mutate_if(is.ordered, ~ as.character(.) %>% as.factor)
ds_test_data_clean
# change cc to factor
ds_test_data <- ds_test_data_clean %>%
mutate(cc = as.factor(cc))
# Split into training, validation and test sets
## 75% of the sample size for train, 12.5% for validation & test
train_size <- floor(0.75 * nrow(ds_test_data))
valid_size <- floor(.50 * (nrow(ds_test_data)-train_size))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(ds_test_data)), size = train_size)
train_tbl <- ds_test_data[train_ind, ]
valid_ind <- sample(seq_len(nrow(ds_test_data[-train_ind, ])), size = valid_size)
valid_tbl <- ds_test_data[valid_ind, ]
test_ind <- sample(seq_len(nrow(ds_test_data[c(-train_ind,-valid_ind), ])), size = valid_size)
test_tbl <- ds_test_data[test_ind, ]
h2o.init()        # Fire up h2o
h2o.no_progress() # Turn off progress bars
# Convert to H2OFrame objects
train_h2o <- as.h2o(train_tbl)
valid_h2o <- as.h2o(valid_tbl)
test_h2o  <- as.h2o(test_tbl)
# Set names for h2o
y <- "cc"
x <- setdiff(names(train_h2o), y)
# linear regression model used, but can use any model
automl_models_h2o <- h2o.automl(
project_name = "your_mom",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
max_runtime_secs = 60,
stopping_metric = "AUC"
, sort_metric = "AUC")
# Extract leader model
automl_leader <- automl_models_h2o@leader
# Get Results
pred_h2o <- h2o.predict(automl_leader, test_h2o)
h2o.performance(automl_leader, test_h2o)
h2o.varimp(automl_leader)
h2o.varimp_plot(automl_leader, 20)
h2o.download_mojo(automl_leader, "~/Downloads/", FALSE)
h2o.confusionMatrix(h2o.performance(automl_leader, test_h2o))
# Generating a Confusion Matrix
h2o.confusionMatrix(h2o.performance(automl_leader, test_h2o))
h2o.varimp_plot(automl_leader, 20)
h2o.partialPlot(automl_leader, data = train_h2o, cols = "jobs_completed")
h2o.varimp_plot(automl_leader, 20)
h2o.varimp(automl_leader)
h2o.varimp_plot(automl_leader, 20)
h2o.download_mojo(automl_leader, "~/Downloads/", FALSE)
h2o.partialPlot(automl_leader, data = train_h2o, cols = "jobs_completed")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "owner_operator")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "cc_rate")
# Generating a Confusion Matrix
h2o.confusionMatrix(h2o.performance(automl_leader, test_h2o))
# RANDOM FOREST
rf_models_h2o <- h2o.randomForest(
# project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
# leaderboard_frame = test_h2o,
max_runtime_secs = 60#,
#stopping_metric = "deviance"
)
pred_h2o <- h2o.predict(rf_models_h2o, test_h2o)
h2o.performance(rf_models_h2o, test_h2o)
h2o.varimp(rf_models_h2o)
h2o.varimp_plot(rf_models_h2o, 20)
h2o.download_mojo(rf_models_h2o, "~/Downloads/", FALSE)
View(ds_test_data)
rf_models_h2o <- h2o.randomForest(
# project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
categorical_encoding = one_hot_explicit,
max_runtime_secs = 60#,
#stopping_metric = "deviance"
)
ds_test_data[-train_ind, ]
valid_no_test_h20 <- as.h20(ds_test_data[-train_ind, ])
h2o.init()        # Fire up h2o
test_h2o  <- as.h2o(test_tbl)
valid_no_test_h20 <- as.h20(ds_test_data[-train_ind, ])
valid_no_test <- ds_test_data[-train_ind, ]
valid_no_test_h20 <- as.h20(valid_no_test)
valid_no_test_h20 <- as.h2o(valid_no_test)
rf_models_h2o <- h2o.randomForest(
# project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_no_test_h20,
categorical_encoding = one_hot_explicit,
max_runtime_secs = 60#,
#stopping_metric = "deviance"
)
rf_models_h2o <- h2o.randomForest(
# project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_no_test_h20,
categorical_encoding = "OneHotInternal",
max_runtime_secs = 60#,
#stopping_metric = "deviance"
)
rf_models_h2o <- h2o.randomForest(
# project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_no_test_h20,
categorical_encoding = "OneHotExplicit",
max_runtime_secs = 60#,
#stopping_metric = "deviance"
)
rf_models_h2o <- h2o.randomForest(
# project_name = "your_moms",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_no_test_h20,
categorical_encoding = "Enum",
max_runtime_secs = 60#,
#stopping_metric = "deviance"
)
ds_test_data <- ds_test_data_clean %>%
mutate(cc = as.factor(cc), vertical = as.factor(vertical), plan_tier = as.factor(plan_tier))
## 75% of the sample size for train, 12.5% for validation & test
train_size <- floor(0.75 * nrow(ds_test_data))
valid_size <- floor(.50 * (nrow(ds_test_data)-train_size))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(ds_test_data)), size = train_size)
train_tbl <- ds_test_data[train_ind, ]
valid_ind <- sample(seq_len(nrow(ds_test_data[-train_ind, ])), size = valid_size)
valid_tbl <- ds_test_data[valid_ind, ]
test_ind <- sample(seq_len(nrow(ds_test_data[c(-train_ind,-valid_ind), ])), size = valid_size)
test_tbl <- ds_test_data[test_ind, ]
valid_no_test <- ds_test_data[-train_ind, ]
h2o.init()        # Fire up h2o
h2o.no_progress() # Turn off progress bars
# Convert to H2OFrame objects
train_h2o <- as.h2o(train_tbl)
valid_h2o <- as.h2o(valid_tbl)
test_h2o  <- as.h2o(test_tbl)
valid_no_test_h20 <- as.h2o(valid_no_test)
# Set names for h2o
y <- "cc"
x <- setdiff(names(train_h2o), y)
# linear regression model used, but can use any model
automl_models_h2o <- h2o.automl(
project_name = "your_mom",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_h2o,
leaderboard_frame = test_h2o,
max_runtime_secs = 60,
stopping_metric = "AUC"
, sort_metric = "AUC")
# Extract leader model
automl_leader <- automl_models_h2o@leader
# Get Results
pred_h2o <- h2o.predict(automl_leader, test_h2o)
h2o.performance(automl_leader, test_h2o)
h2o.varimp(automl_leader)
h2o.varimp_plot(automl_leader, 20)
h2o.download_mojo(automl_leader, "~/Downloads/", FALSE)
h2o.partialPlot(automl_leader, data = train_h2o, cols = "jobs_completed")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "owner_operator")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "cc_rate")
# Generating a Confusion Matrix
h2o.confusionMatrix(h2o.performance(automl_leader, test_h2o))
pred_h2o <- h2o.predict(automl_leader, test_h2o)
h2o.performance(automl_leader, test_h2o)
h2o.varimp(automl_leader)
h2o.varimp_plot(automl_leader, 20)
h2o.download_mojo(automl_leader, "~/Downloads/", FALSE)
h2o.partialPlot(automl_leader, data = train_h2o, cols = "jobs_completed")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "owner_operator")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "cc_rate")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "vertical")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "plan_tier")
# Generating a Confusion Matrix
h2o.confusionMatrix(h2o.performance(automl_leader, test_h2o))
# Investigate test error
error_tbl <- my_ts %>% mutate(index = date(index)) %>%
# filter(between(lubridate::year(index), 2015, 2018)) %>%
filter((lubridate::year(index) >= 2018 & lubridate::month(index) >= 7) | (lubridate::year(index) == 2019)) %>%
add_column(pred = pred_h2o %>% as.tibble() %>% pull(predict)) %>%
rename(actual = Cash) %>%
mutate(
error     = actual - pred,
error_pct = error / actual
)
# RANDOM FOREST
rf_models_h2o <- h2o.randomForest(
project_name = "ds_test_models",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_no_test_h20,
categorical_encoding = "Enum",
max_runtime_secs = 60,
stopping_metric = "AUC"
)
rf_models_h2o <- h2o.randomForest(
project_name = "ds_test_models",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_no_test_h20,
categorical_encoding = "Enum",
max_runtime_secs = 60,
stopping_metric = "AUC"
)
rf_models_h2o <- h2o.randomForest(
# project_name = "ds_test_models",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_no_test_h20,
categorical_encoding = "Enum",
max_runtime_secs = 60,
stopping_metric = "AUC"
)
rf_models_h2o <- h2o.randomForest(
# project_name = "ds_test_models",
x = x,
y = y,
training_frame = train_h2o,
validation_frame = valid_no_test_h20,
categorical_encoding = "Enum",
max_runtime_secs = 60
)
pred_h2o <- h2o.predict(rf_models_h2o, test_h2o)
h2o.performance(rf_models_h2o, test_h2o)
h2o.varimp(rf_models_h2o)
h2o.varimp_plot(rf_models_h2o, 20)
h2o.gainsLift(automl_leader, train_h2o)
pred_h2o <- h2o.predict(automl_leader, test_h2o)
h2o.performance(automl_leader, test_h2o)
h2o.varimp(automl_leader)
h2o.varimp_plot(automl_leader, 20)
h2o.download_mojo(automl_leader, "~/Downloads/", FALSE)
h2o.partialPlot(automl_leader, data = train_h2o, cols = "jobs_completed")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "owner_operator")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "cc_rate")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "vertical")
h2o.partialPlot(automl_leader, data = train_h2o, cols = "plan_tier")
# Load libraries
library(h2o)        # Awesome ML Library
library(timetk)     # Toolkit for working with time series in R
library(tidyquant)  # Loads tidyverse, financial pkgs, used to get data
library(dplyr)
library(h2o)
ds_test_data <- readRDS("~/Downloads/Data_Scientist_Test_Data_source_0.rds")
setwd("~/Documents/sites/academic-kickstart")
blogdown::build_site()
